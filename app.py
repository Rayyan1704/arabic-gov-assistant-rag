"""
Streamlit Demo App for Arabic Government Services RAG
"""
import streamlit as st
import sys
sys.path.append('src')

from sentence_transformers import SentenceTransformer
from category_retrieval import RerankedRetriever
from llm_generator import AnswerGenerator

# Page config
st.set_page_config(
    page_title="AraGovAssist",
    page_icon="ğŸ‡¶ğŸ‡¦",
    layout="wide"
)

# Title
st.title("ğŸ‡¶ğŸ‡¦ AraGovAssist")
st.markdown("*Arabic Government Services Intelligent Assistant*")
st.markdown("---")

# Load models (cache for performance)
@st.cache_resource
def load_models():
    """Load all models (cached)"""
    try:
        model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')
        
        retriever = RerankedRetriever(
            'index/embeddings.npy',
            'index/corpus_chunks.json',
            'index/corpus_meta.json'
        )
        
        generator = AnswerGenerator()
        
        return model, retriever, generator
    except Exception as e:
        st.error(f"Error loading models: {e}")
        return None, None, None

with st.spinner("ğŸ”„ Loading models..."):
    model, retriever, generator = load_models()

if model and retriever and generator:
    st.success("âœ… System ready!")
else:
    st.error("âŒ Failed to load models. Check your setup.")
    st.stop()

# Settings in sidebar
with st.sidebar:
    st.header("âš™ï¸ Settings")
    
    use_category = st.checkbox("Enable category detection", value=True)
    use_reranking = st.checkbox("Enable reranking", value=True)
    use_llm = st.checkbox("Generate AI answer", value=True)
    num_results = st.slider("Number of sources", 1, 10, 3)
    
    st.markdown("---")
    st.markdown("**ğŸ“Š Statistics**")
    st.metric("Documents", "34")
    st.metric("Categories", "8")
    st.metric("Retrieval Accuracy", "100%")
    
    st.markdown("---")
    st.markdown("**â„¹ï¸ About**")
    st.markdown("Multilingual RAG system for Qatar government services using:")
    st.markdown("- Semantic search (FAISS)")
    st.markdown("- Cross-encoder reranking")
    st.markdown("- Gemini AI generation")

# Main input
query = st.text_input(
    "Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§ / Enter your question:",
    placeholder="Ù…Ø«Ø§Ù„: ÙƒÙŠÙ Ø£Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø±Ø®ØµØ© Ù„ÙŠÙ…ÙˆØ²ÙŠÙ† ÙÙŠ Ù‚Ø·Ø±ØŸ"
)

# Process query
if st.button("ğŸ” Search", type="primary") and query:
    with st.spinner("ğŸ” Searching..."):
        # Get query embedding
        query_emb = model.encode([query])[0]
        
        # Detect category
        category = None
        if use_category:
            category = retriever.detect_category(query)
            if category:
                st.info(f"ğŸ“ Detected category: **{category}**")
        
        # Retrieve
        if use_reranking:
            results = retriever.search_with_rerank(
                query, query_emb,
                category=category,
                initial_k=20,
                final_k=num_results
            )
        else:
            results = retriever.search(
                query_emb,
                category=category,
                k=num_results
            )
        
        # Generate answer if enabled
        if use_llm:
            with st.spinner("ğŸ¤– Generating answer..."):
                try:
                    answer_data = generator.generate_answer(query, results)
                    
                    # Display answer
                    st.markdown("### ğŸ“ Answer")
                    st.markdown(answer_data['answer'])
                except Exception as e:
                    st.warning(f"Could not generate answer: {e}")
                    st.info("Showing retrieved documents instead.")
        
        # Display sources
        st.markdown("### ğŸ“š Sources")
        for i, result in enumerate(results, 1):
            score_text = f"Score: {result['score']:.3f}"
            if 'rerank_score' in result:
                score_text += f" | Rerank: {result['rerank_score']:.3f}"
            
            with st.expander(f"Source {i}: {result['metadata']['category']} ({score_text})"):
                st.markdown(f"**File:** `{result['metadata']['source_file'].split('/')[-1]}`")
                st.markdown(f"**Search Type:** {result.get('search_type', 'N/A')}")
                st.markdown(f"**Content:**")
                st.text(result['chunk'])

# Example queries
st.markdown("---")
st.markdown("### ğŸ’¡ Example Queries")

examples = [
    "ÙƒÙŠÙ Ø£Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø±Ø®ØµØ© Ù„ÙŠÙ…ÙˆØ²ÙŠÙ† ÙÙŠ Ù‚Ø·Ø±ØŸ",
    "Ù…Ø§ Ù‡ÙŠ Ø®Ø·ÙˆØ§Øª ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø±Ø±Ø§Øª ÙÙŠ Ø¬Ø§Ù…Ø¹Ø© Ù‚Ø·Ø±ØŸ",
    "ÙƒÙŠÙ Ø£Ø·Ù„Ø¨ Ø§Ø³ØªØ´Ø§Ø±Ø© Ø·Ø¨ÙŠØ© Ø¹Ø§Ø¬Ù„Ø©ØŸ",
    "ÙƒÙŠÙ Ø£Ù‚Ø¯Ù… Ø¹Ø±ÙˆØ¶ Ø§Ù„Ù…Ù†Ø§Ù‚ØµØ§ØªØŸ",
    "Ù…Ø§ Ù‡ÙŠ Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø´Ù‡Ø§Ø¯Ø© CRAØŸ"
]

cols = st.columns(len(examples))
for i, example in enumerate(examples):
    with cols[i]:
        if st.button(example, key=f"ex_{i}", use_container_width=True):
            st.session_state.query = example
            st.rerun()

# Footer
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: gray;'>"
    "Built with â¤ï¸ using Streamlit, FAISS, and Gemini AI | "
    "<a href='https://github.com/Rayyan1704/arabic-gov-assistant-rag'>GitHub</a>"
    "</div>",
    unsafe_allow_html=True
)
