{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5eeabeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG Pipeline (Offline Version, No OpenAI Required)\n",
    "# Notebook: 01_rag_no_openai.ipynb\n",
    "# ------------------------------------------------------\n",
    "# This notebook implements a full Arabic-focused RAG pipeline\n",
    "# that uses ONLY local / open-source tools:\n",
    "# - sentence-transformers (e5 multilingual)\n",
    "# - HuggingFace M2M100 for translation\n",
    "# - langdetect for language detection\n",
    "# - FAISS for vector search\n",
    "# - CrossEncoder (MS MARCO) for reranking\n",
    "# - No OpenAI API used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57380569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# Cell 1 — Install dependencies\n",
    "# ------------------------------------------------------\n",
    "!pip install sentence-transformers faiss-cpu langdetect arabic-reshaper transformers torch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c666718a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: 'Could not load this library: C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\torchvision\\image.pyd'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: 'Could not load this library: C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\torchvision\\image.pyd'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# Cell 2 — Imports\n",
    "# ------------------------------------------------------\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import faiss\n",
    "from langdetect import detect\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed261c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# Cell 3 — Config\n",
    "# ------------------------------------------------------\n",
    "DATA_DIR = \"../data\"\n",
    "INDEX_DIR = \"../index_no_openai\"\n",
    "os.makedirs(INDEX_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "EMBED_MODEL = \"intfloat/multilingual-e5-base\"\n",
    "CHUNK_SIZE = 900\n",
    "CHUNK_OVERLAP = 150\n",
    "\n",
    "\n",
    "CATEGORIES = [\"business\",\"culture\",\"education\",\"health\",\"housing\",\"info\",\"justice\",\"transportation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3126c67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 34 text files.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# Cell 4 — File Loader\n",
    "# ------------------------------------------------------\n",
    "\n",
    "def list_text_files():\n",
    "    files = sorted(glob.glob(os.path.join(DATA_DIR, \"**/*.txt\"), recursive=True))\n",
    "    return files\n",
    "\n",
    "files = list_text_files()\n",
    "print(f\"Loaded {len(files)} text files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d07c461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories: {'culture', 'health', 'business', 'housing', 'transportation', 'education', 'info', 'justice'}\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# Cell 5 — Read Documents into Memory\n",
    "# ------------------------------------------------------\n",
    "\n",
    "documents = []\n",
    "for f in files:\n",
    "    rel = os.path.relpath(f, DATA_DIR)\n",
    "    parts = rel.split(os.sep)\n",
    "    category = parts[0].lower() if len(parts) > 1 else \"info\"\n",
    "    with open(f, 'r', encoding='utf-8') as fh:\n",
    "        txt = fh.read().strip()\n",
    "    documents.append({\n",
    "        \"path\": f,\n",
    "        \"category\": category,\n",
    "        \"filename\": os.path.basename(f),\n",
    "        \"text\": txt\n",
    "    })\n",
    "\n",
    "print(\"Categories:\", set(d['category'] for d in documents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a26040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# Cell 6 — Paragraph + Smart Chunking\n",
    "# ------------------------------------------------------\n",
    "\n",
    "def para_split(text):\n",
    "    paras = re.split(r\"\\n\\s*\\n\", text)\n",
    "    return [p.strip() for p in paras if p.strip()]\n",
    "\n",
    "def smart_chunk_text(text, chunk_size=CHUNK_SIZE, overlap=CHUNK_OVERLAP, min_size=200):\n",
    "    paras = para_split(text)\n",
    "    chunks = []\n",
    "    buffer = \"\"\n",
    "\n",
    "    for p in paras:\n",
    "        if len(buffer) + len(p) + 1 <= chunk_size:\n",
    "            buffer = (buffer + \"\\n\\n\" + p).strip() if buffer else p\n",
    "        else:\n",
    "            if len(buffer) >= min_size:\n",
    "                chunks.append(buffer)\n",
    "            buffer = p\n",
    "\n",
    "    if buffer and len(buffer) >= min_size:\n",
    "        chunks.append(buffer)\n",
    "\n",
    "    # Sliding window if needed\n",
    "    final_chunks = []\n",
    "    for ch in chunks:\n",
    "        if len(ch) <= chunk_size:\n",
    "            final_chunks.append(ch)\n",
    "        else:\n",
    "            start = 0\n",
    "            while start < len(ch):\n",
    "                end = start + chunk_size\n",
    "                final_chunks.append(ch[start:end])\n",
    "                if end >= len(ch):\n",
    "                    break\n",
    "                start = end - overlap\n",
    "\n",
    "    return final_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66d2e02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 45\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# Cell 7 — Build Corpus Chunks\n",
    "# ------------------------------------------------------\n",
    "\n",
    "corpus_chunks = []\n",
    "corpus_meta = []\n",
    "\n",
    "for doc in documents:\n",
    "    chunks = smart_chunk_text(doc['text'])\n",
    "    for i, ch in enumerate(chunks):\n",
    "        corpus_chunks.append(ch)\n",
    "        corpus_meta.append({\n",
    "            \"file\": doc['filename'],\n",
    "            \"path\": doc['path'],\n",
    "            \"category\": doc['category'],\n",
    "            \"chunk_id\": i\n",
    "        })\n",
    "\n",
    "print(\"Total chunks:\", len(corpus_chunks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aeb75067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model loaded.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# Cell 8 — Load Embedding Model\n",
    "# ------------------------------------------------------\n",
    "\n",
    "model = SentenceTransformer(EMBED_MODEL)\n",
    "print(\"Embedding model loaded.\")\n",
    "\n",
    "# FIX: Add keyword boosting\n",
    "KEYWORDS = {\n",
    "    \"transportation\": \"مواصلات نقل مركبات سيارات ليموزين شحن طرود تراخيص سفر\",\n",
    "    \"business\": \"تجارة شركات رخصة سجل تجاري تمويل شركة مستندات\",\n",
    "    \"education\": \"جامعة طلاب مقررات تسجيل قبول كشوف درجات\",\n",
    "    \"health\": \"طبي صحة تقرير حمد استشارة ترخيص ممارس\",\n",
    "    \"justice\": \"محكمة دعوى مرافعة قضية قانون عدالة\",\n",
    "    \"housing\": \"إسكان سند ملكية سكن منزل\",\n",
    "    \"culture\": \"تصوير تلفزيون أفلام ترخيص إعلام\",\n",
    "    \"info\": \"شارك استبيان استطلاع حكومي معلومات\",\n",
    "}\n",
    "\n",
    "def prep(c, m):\n",
    "    kw = KEYWORDS.get(m[\"category\"], \"\")\n",
    "    return (\n",
    "        f\"passage: document={m['file']} category={m['category']}\\n\"\n",
    "        f\"keywords: {kw}\\n\\n\"\n",
    "        f\"{c}\"\n",
    "    )\n",
    "\n",
    "prepared_chunks = [prep(c, m) for c, m in zip(corpus_chunks, corpus_meta)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0111b1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:17<00:00, 17.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: (45, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# Cell 9 — Embed Chunks\n",
    "# ------------------------------------------------------\n",
    "\n",
    "\n",
    "embeddings = model.encode(prepared_chunks, batch_size=64, show_progress_bar=True)\n",
    "embeddings = embeddings.astype('float32')\n",
    "print('Embeddings:', embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "030ebc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes built.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# Cell 10 — Build Per-Category Indexes\n",
    "# ------------------------------------------------------\n",
    "\n",
    "indexes = {}\n",
    "for cat in CATEGORIES + [\"all\"]:\n",
    "    indexes[cat] = {\n",
    "        \"index\": faiss.IndexFlatL2(embeddings.shape[1]),\n",
    "        \"ids\": []\n",
    "    }\n",
    "\n",
    "for global_id, meta in enumerate(corpus_meta):\n",
    "    vec = embeddings[global_id:global_id+1]\n",
    "    cat = meta['category']\n",
    "    indexes[cat]['index'].add(vec)\n",
    "    indexes[cat]['ids'].append(global_id)\n",
    "    indexes['all']['index'].add(vec)\n",
    "    indexes['all']['ids'].append(global_id)\n",
    "\n",
    "print(\"Indexes built.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5780f75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translator ready.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# Cell 11 — Load Translation Model (M2M100)\n",
    "# ------------------------------------------------------\n",
    "\n",
    "# Ensure sentencepiece is installed for the tokenizer\n",
    "!pip install sentencepiece --quiet\n",
    "\n",
    "translator = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")\n",
    "\n",
    "print(\"Translator ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9546bac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# Cell 12 — Translation Helpers\n",
    "# ------------------------------------------------------\n",
    "\n",
    "def translate_to_ar(text):\n",
    "    tokenizer.src_lang = \"en\"\n",
    "    enc = tokenizer(text, return_tensors=\"pt\")\n",
    "    out = translator.generate(**enc, forced_bos_token_id=tokenizer.get_lang_id(\"ar\"))\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "def translate_to_en(text):\n",
    "    tokenizer.src_lang = \"ar\"\n",
    "    enc = tokenizer(text, return_tensors=\"pt\")\n",
    "    out = translator.generate(**enc, forced_bos_token_id=tokenizer.get_lang_id(\"en\"))\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f110563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# Cell 13 — Arabic Normalization\n",
    "# ------------------------------------------------------\n",
    "\n",
    "import arabic_reshaper\n",
    "\n",
    "\n",
    "def normalize_ar(text):\n",
    "    text = re.sub(r\"[ًٌٍَُِّْ]\", \"\", text)  # remove diacritics\n",
    "    text = text.replace(\"أ\", \"ا\").replace(\"إ\", \"ا\").replace(\"آ\", \"ا\")\n",
    "    text = text.replace(\"ى\", \"ي\")\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9ec6dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# Cell 14 — Category Detection (Rule-Based)\n",
    "# ------------------------------------------------------\n",
    "\n",
    "\n",
    "def detect_category(query):\n",
    "    q = query\n",
    "    if any(k in q for k in ['ليموزين','سيارة','مواصلات','شحن','طرود']): return 'transportation'\n",
    "    if any(k in q for k in ['جامعة','مقررات','قبول','كشف','transcript']): return 'education'\n",
    "    if any(k in q for k in ['طبيب','حمد','طبي','استشارة']): return 'health'\n",
    "    if any(k in q for k in ['رخصة','سجل','تمويل','قرض','شركة']): return 'business'\n",
    "    if any(k in q for k in ['ملكية','اسكان','سند']): return 'housing'\n",
    "    if any(k in q for k in ['شارك','استبيان','استطلاع','مشاركة']): return 'info'\n",
    "    if any(k in q for k in ['دعوى','مرافعة','محكمة']):  return 'justice'\n",
    "    if any(k in q for k in [\"limousine\", \"rent car\", \"car hire\", \"limo\", \"vehicle\"]):  return \"transportation\"\n",
    "    if any(k in q for k in [\"university\", \"register\", \"courses\"]):  return \"education\"\n",
    "    return 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f921afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranker loaded.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# Cell 15 — Load Cross-Encoder Reranker\n",
    "# ------------------------------------------------------\n",
    "\n",
    "\n",
    "reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "print(\"Reranker loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04bc35dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# Cell 16 — Retrieval Function (with Fix #2)\n",
    "# ------------------------------------------------------\n",
    "\n",
    "def retrieve(query, top_k=5, use_category=True):\n",
    "\n",
    "    # 1 — Detect language\n",
    "    lang = detect(query)\n",
    "    original_query = query\n",
    "\n",
    "    # 2 — Translate EN → AR\n",
    "    if lang.startswith(\"en\"):\n",
    "        query = translate_to_ar(query)\n",
    "\n",
    "    # 3 — Normalize Arabic\n",
    "    query = normalize_ar(query)\n",
    "\n",
    "    # 4 — Category detection\n",
    "    cat = detect_category(query) if use_category else \"all\"\n",
    "    index_obj = indexes.get(cat, indexes[\"all\"])\n",
    "\n",
    "    # 5 — Embed query\n",
    "    q_embed = model.encode([f\"query: {query}\"], convert_to_numpy=True)\n",
    "    q_embed = q_embed.astype(\"float32\")\n",
    "\n",
    "    # ------------------------------\n",
    "    # FIX #2 — Retrieve more candidates\n",
    "    # ------------------------------\n",
    "    FAISS_K = 40   # instead of top_k (5)\n",
    "    D, I = index_obj[\"index\"].search(q_embed, FAISS_K)\n",
    "\n",
    "    # 6 — Map to global chunk IDs\n",
    "    candidates = []\n",
    "    for local_id in I[0]:\n",
    "        global_id = index_obj[\"ids\"][local_id]\n",
    "        candidates.append({\n",
    "            \"meta\": corpus_meta[global_id],\n",
    "            \"text\": corpus_chunks[global_id]\n",
    "        })\n",
    "\n",
    "    # 7 — Rerank with cross-encoder\n",
    "    pairs = [(query, c[\"text\"]) for c in candidates]\n",
    "    scores = reranker.predict(pairs)\n",
    "\n",
    "    ranked = [\n",
    "        x for _, x in sorted(\n",
    "            zip(scores, candidates),\n",
    "            key=lambda x: x[0],\n",
    "            reverse=True\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # return final best 3\n",
    "    return ranked[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8011846a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== QUERY === How can I rent a limousine in Qatar?\n",
      "FILE: transportation_fish_transport_permit.txt | CATEGORY: transportation\n",
      "# طلب إصدار ترخيص وسيلة نقل أسماك  **مقدّم الخدمة:**   وزارة البلدية  **نوع الخدمة:**   خدمة ورقية – تقديم شخصي  ## وصف الخدمة يمكن لمالكي السفن وقوارب الصيد تقديم طلب إصدار ترخيص نقل أسماك داخل دولة  ...\n",
      "FILE: transportation_ag_vehicle_circulation_request.txt | CATEGORY: transportation\n",
      "# طلب تعميم على مركبة  **مقدّم الخدمة:**   النيابة العامة  **نوع الخدمة:**   خدمة إلكترونية – تقديم عبر الإنترنت  ## وصف الخدمة تتيح هذه الخدمة التعميم على مركبة عبر النيابة العامة.  ## الإرشادات - ال ...\n",
      "FILE: transportation_qpost_cargo_service.txt | CATEGORY: transportation\n",
      "# خدمة الشحن من \"بريد قطر\"  **مقدّم الخدمة:**   الشركة القطرية للخدمات البريدية (بريد قطر)  **نوع الخدمة:**   خدمة إلكترونية – تقديم عبر الإنترنت  ## وصف الخدمة تُقدِّم الشركةُ القطريةُ للخدمات البريد ...\n",
      "\n",
      "=== QUERY === كيف اسجل في مقررات جامعة قطر؟\n",
      "FILE: transportation_fish_transport_permit.txt | CATEGORY: transportation\n",
      "# طلب إصدار ترخيص وسيلة نقل أسماك  **مقدّم الخدمة:**   وزارة البلدية  **نوع الخدمة:**   خدمة ورقية – تقديم شخصي  ## وصف الخدمة يمكن لمالكي السفن وقوارب الصيد تقديم طلب إصدار ترخيص نقل أسماك داخل دولة  ...\n",
      "FILE: transportation_ag_vehicle_circulation_request.txt | CATEGORY: transportation\n",
      "# طلب تعميم على مركبة  **مقدّم الخدمة:**   النيابة العامة  **نوع الخدمة:**   خدمة إلكترونية – تقديم عبر الإنترنت  ## وصف الخدمة تتيح هذه الخدمة التعميم على مركبة عبر النيابة العامة.  ## الإرشادات - ال ...\n",
      "FILE: transportation_qpost_cargo_service.txt | CATEGORY: transportation\n",
      "# خدمة الشحن من \"بريد قطر\"  **مقدّم الخدمة:**   الشركة القطرية للخدمات البريدية (بريد قطر)  **نوع الخدمة:**   خدمة إلكترونية – تقديم عبر الإنترنت  ## وصف الخدمة تُقدِّم الشركةُ القطريةُ للخدمات البريد ...\n",
      "\n",
      "=== QUERY === كيف اسجل في مقررات جامعة قطر؟\n",
      "FILE: education_qu_transcript_request.txt | CATEGORY: education\n",
      "# طلب ومتابعة كشف الدرجات لطلاب جامعة قطر المقيديين غير الخريجين  **مقدّم الخدمة:**   جامعة قطر  **نوع الخدمة:**   خدمة إلكترونية – تقديم عبر الإنترنت  **نظام التقديم:**   إلكتروني  ## وصف الخدمة تُتي ...\n",
      "FILE: education_qu_course_registration.txt | CATEGORY: education\n",
      "# طلب تسجيل المقررات الدراسية في جامعة قطر  **مقدّم الخدمة:**   جامعة قطر  **نوع الخدمة:**   خدمة إلكترونية – تقديم عبر الإنترنت  **نظام التقديم:**   إلكتروني  ## وصف الخدمة يُعتبرُ التسجيلُ في المقرر ...\n",
      "FILE: education_qu_withdrawal_request.txt | CATEGORY: education\n",
      "# طلب الانسحاب من جامعة قطر  **مقدّم الخدمة:**   جامعة قطر  **نوع الخدمة:**   خدمة إلكترونية – تقديم عبر الإنترنت  **نظام التقديم:**   إلكتروني  ## وصف الخدمة يمكن للطلاب في جامعة قطر تقديم طلب للانسح ...\n",
      "\n",
      "=== QUERY === ما هي رسوم تجديد رخصة مكتب سفر؟\n",
      "FILE: education_qu_transcript_request.txt | CATEGORY: education\n",
      "# طلب ومتابعة كشف الدرجات لطلاب جامعة قطر المقيديين غير الخريجين  **مقدّم الخدمة:**   جامعة قطر  **نوع الخدمة:**   خدمة إلكترونية – تقديم عبر الإنترنت  **نظام التقديم:**   إلكتروني  ## وصف الخدمة تُتي ...\n",
      "FILE: education_qu_course_registration.txt | CATEGORY: education\n",
      "# طلب تسجيل المقررات الدراسية في جامعة قطر  **مقدّم الخدمة:**   جامعة قطر  **نوع الخدمة:**   خدمة إلكترونية – تقديم عبر الإنترنت  **نظام التقديم:**   إلكتروني  ## وصف الخدمة يُعتبرُ التسجيلُ في المقرر ...\n",
      "FILE: education_qu_withdrawal_request.txt | CATEGORY: education\n",
      "# طلب الانسحاب من جامعة قطر  **مقدّم الخدمة:**   جامعة قطر  **نوع الخدمة:**   خدمة إلكترونية – تقديم عبر الإنترنت  **نظام التقديم:**   إلكتروني  ## وصف الخدمة يمكن للطلاب في جامعة قطر تقديم طلب للانسح ...\n",
      "\n",
      "=== QUERY === ما هي رسوم تجديد رخصة مكتب سفر؟\n",
      "FILE: business_moci_license_reactivation.txt | CATEGORY: business\n",
      "## معلومات إضافية - الوثائق المطلوبة يجب أن تكون مرفقة وفق الصيغ المسموح بها وبحجم مناسب.   - ساعات العمل الرسمي: من الأحد إلى الخميس.   - الفئات المستفيدة من الخدمة: المستثمرون المحليون الذين لديهم ر ...\n",
      "FILE: business_moci_import_pesticides.txt | CATEGORY: business\n",
      "## معلومات إضافية - الخدمة متاحة أيضًا عبر تطبيق الجوال \"عون\".   - الوقت المتوقع لإنجاز الخدمة: 3 أيام عمل.   - الخدمة موجّهة للشركات فقط.   - يجب أن يكون نشاط الشركة يشمل تجارة واستيراد المبيدات الزر ...\n",
      "FILE: business_moci_patent_data_request.txt | CATEGORY: business\n",
      "# طلب بيانات أو مستخرجات أو صور لبراءة اختراع  **مقدّم الخدمة:**   وزارة التجارة والصناعة  **نوع الخدمة:**   خدمة إلكترونية – تقديم عبر الإنترنت  **نظام التقديم:**   إلكتروني  **تاريخ النشر:**   11 ين ...\n",
      "FILE: business_moci_license_reactivation.txt | CATEGORY: business\n",
      "## معلومات إضافية - الوثائق المطلوبة يجب أن تكون مرفقة وفق الصيغ المسموح بها وبحجم مناسب.   - ساعات العمل الرسمي: من الأحد إلى الخميس.   - الفئات المستفيدة من الخدمة: المستثمرون المحليون الذين لديهم ر ...\n",
      "FILE: business_moci_import_pesticides.txt | CATEGORY: business\n",
      "## معلومات إضافية - الخدمة متاحة أيضًا عبر تطبيق الجوال \"عون\".   - الوقت المتوقع لإنجاز الخدمة: 3 أيام عمل.   - الخدمة موجّهة للشركات فقط.   - يجب أن يكون نشاط الشركة يشمل تجارة واستيراد المبيدات الزر ...\n",
      "FILE: business_moci_patent_data_request.txt | CATEGORY: business\n",
      "# طلب بيانات أو مستخرجات أو صور لبراءة اختراع  **مقدّم الخدمة:**   وزارة التجارة والصناعة  **نوع الخدمة:**   خدمة إلكترونية – تقديم عبر الإنترنت  **نظام التقديم:**   إلكتروني  **تاريخ النشر:**   11 ين ...\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# Cell 17 — Test\n",
    "# ------------------------------------------------------\n",
    "\n",
    "qs = [\n",
    "    \"How can I rent a limousine in Qatar?\",  # English test\n",
    "    \"كيف اسجل في مقررات جامعة قطر؟\",  # Arabic\n",
    "    \"ما هي رسوم تجديد رخصة مكتب سفر؟\",\n",
    "]\n",
    "\n",
    "for q in qs:\n",
    "    print(\"\\n=== QUERY ===\", q)\n",
    "    results = retrieve(q, top_k=5)\n",
    "    for r in results:\n",
    "        print(\"FILE:\", r['meta']['file'], \"| CATEGORY:\", r['meta']['category'])\n",
    "        print(r['text'][:200].replace('\\n', ' '), '...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149a62a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
