{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Processing\n",
    "Process all documents into chunks with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from chunking import chunk_document\n",
    "from preprocessing import normalize_arabic\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all documents\n",
    "all_chunks = []\n",
    "metadata = []\n",
    "\n",
    "categories = ['health', 'education', 'business', 'transportation', 'justice', 'housing', 'culture', 'info']\n",
    "\n",
    "for cat in categories:\n",
    "    files = glob.glob(f'../data/{cat}/*.txt')\n",
    "    \n",
    "    for filepath in files:\n",
    "        try:\n",
    "            chunks = chunk_document(filepath, chunk_size=512, overlap=128)\n",
    "            \n",
    "            for i, chunk in enumerate(chunks):\n",
    "                all_chunks.append(chunk)\n",
    "                metadata.append({\n",
    "                    'source_file': filepath,\n",
    "                    'category': cat,\n",
    "                    'chunk_id': i,\n",
    "                    'chunk_length': len(chunk)\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filepath}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total documents: {len(set(m['source_file'] for m in metadata))}\")\n",
    "print(f\"Total chunks: {len(all_chunks)}\")\n",
    "print(f\"\\nChunks per category:\")\n",
    "for cat in categories:\n",
    "    count = len([m for m in metadata if m['category'] == cat])\n",
    "    print(f\"  {cat}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "with open('../index/corpus_chunks.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_chunks, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open('../index/corpus_meta.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\nâœ… Saved to index/ directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample inspection\n",
    "print(\"\\n=== Sample Chunk ===\")\n",
    "print(f\"Category: {metadata[0]['category']}\")\n",
    "print(f\"Length: {metadata[0]['chunk_length']}\")\n",
    "print(f\"\\nContent:\\n{all_chunks[0][:300]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
