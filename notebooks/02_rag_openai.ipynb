{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a73447de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02_rag_openai.ipynb\n",
    "# OpenAI-enabled version of the RAG pipeline.\n",
    "# Same structure as the offline notebook, but adds:\n",
    "# - OpenAI translation\n",
    "# - OpenAI LLM answer synthesis\n",
    "# - OpenAI reranking (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7777157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# Cell 1 — Install dependencies\n",
    "# ------------------------------------------------------\n",
    "%pip install sentence-transformers faiss-cpu langdetect arabic-reshaper transformers torch openai python-bidi --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6265db1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: 'Could not load this library: C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\Lib\\site-packages\\torchvision\\image.pyd'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Cell 2 — Imports\n",
    "# -----------------------------\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from langdetect import detect\n",
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898fb8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample document categories: ['education', 'business', 'housing', 'health', 'justice', 'info', 'culture', 'transportation']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Cell 3 — Config\n",
    "# -----------------------------\n",
    "DATA_DIR = \"../data\"\n",
    "INDEX_DIR = \"../index_openai\"\n",
    "os.makedirs(INDEX_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "EMBED_MODEL = \"intfloat/multilingual-e5-base\"\n",
    "CHUNK_SIZE = 900\n",
    "CHUNK_OVERLAP = 150\n",
    "CATEGORIES = [\"business\",\"culture\",\"education\",\"health\",\"housing\",\"info\",\"justice\",\"transportation\"]\n",
    "\n",
    "\n",
    "# OpenAI client\n",
    "oi = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef0537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Cell 4 — Language tools\n",
    "# -----------------------------\n",
    "def detect_lang(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return \"ar\"\n",
    "\n",
    "\n",
    "# Local translation fallback (M2M100)\n",
    "m2m_tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")\n",
    "m2m_model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n",
    "\n",
    "\n",
    "def translate_local(text, src=\"en\", tgt=\"ar\"):\n",
    "    m2m_tokenizer.src_lang = src\n",
    "    encoded = m2m_tokenizer(text, return_tensors=\"pt\")\n",
    "    generated = m2m_model.generate(**encoded, forced_bos_token_id=m2m_tokenizer.get_lang_id(tgt))\n",
    "    return m2m_tokenizer.batch_decode(generated, skip_special_tokens=True)[0]\n",
    "\n",
    "\n",
    "# OpenAI translation (preferred)\n",
    "def translate_openai(text, tgt=\"ar\"):\n",
    "    try:\n",
    "        resp = oi.responses.create(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            input=f\"Translate to {tgt}: {text}\"\n",
    "        )\n",
    "        return resp.output_text.strip()\n",
    "    except:\n",
    "        return translate_local(text, \"en\", tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8563e4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Cell 5 — Arabic normalization\n",
    "# -----------------------------\n",
    "def normalize_arabic(text):\n",
    "    text = re.sub(r\"[أإآا]\", \"ا\", text)\n",
    "    text = text.replace(\"ى\", \"ي\").replace(\"ئ\", \"ي\").replace(\"ؤ\", \"و\")\n",
    "    text = re.sub(r\"[\\u064B-\\u0652]\", \"\", text)\n",
    "    text = re.sub(r\"[^0-9A-Za-zءاأإآبتثجحخدذرزسشصضطظعغفقكلمنهوية\\s]\", \" \", text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a3ad70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample length: 1379\n",
      "Chunks sample: 2\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Cell 6 — Load files\n",
    "# -----------------------------\n",
    "def list_files():\n",
    "    return sorted(glob.glob(os.path.join(DATA_DIR, \"**/*.txt\"), recursive=True))\n",
    "\n",
    "\n",
    "files = list_files()\n",
    "print(\"Files found:\", len(files))\n",
    "\n",
    "\n",
    "documents = []\n",
    "for f in files:\n",
    "    rel = os.path.relpath(f, DATA_DIR)\n",
    "    parts = rel.split(os.sep)\n",
    "    category = parts[0] if len(parts) > 1 else \"info\"\n",
    "    with open(f, \"r\", encoding=\"utf-8\") as fh:\n",
    "        text = fh.read().strip()\n",
    "    documents.append({\"file\": os.path.basename(f), \"path\": f, \"category\": category, \"text\": text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3599590d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 44\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Cell 7 — Chunking\n",
    "# -----------------------------\n",
    "def para_split(text):\n",
    "    return [p.strip() for p in re.split(r\"\\n\\s*\\n\", text) if p.strip()]\n",
    "\n",
    "\n",
    "def smart_chunk(text, size=CHUNK_SIZE, overlap=CHUNK_OVERLAP):\n",
    "    paras = para_split(text)\n",
    "    chunks, buf = [], \"\"\n",
    "    for p in paras:\n",
    "        if len(buf) + len(p) <= size:\n",
    "            buf = buf + \"\\n\\n\" + p if buf else p\n",
    "        else:\n",
    "            chunks.append(buf)\n",
    "            buf = p\n",
    "    if buf:\n",
    "        chunks.append(buf)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "corpus_chunks = []\n",
    "corpus_meta = []\n",
    "\n",
    "\n",
    "for d in documents:\n",
    "    chs = smart_chunk(d[\"text\"])\n",
    "    for i, ch in enumerate(chs):\n",
    "        corpus_chunks.append(ch)\n",
    "        corpus_meta.append({\"file\": d[\"file\"], \"category\": d[\"category\"], \"chunk_id\": i})\n",
    "\n",
    "\n",
    "print(\"Total chunks:\", len(corpus_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0831cc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: intfloat/multilingual-e5-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub\\models--intfloat--multilingual-e5-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Cell 8 — Embeddings\n",
    "# -----------------------------\n",
    "model = SentenceTransformer(EMBED_MODEL)\n",
    "print(\"Loaded embedding model.\")\n",
    "\n",
    "\n",
    "BATCH = 64\n",
    "prepared = [f\"document: {m['file']} category: {m['category']}\\n\\n{c}\" for c,m in zip(corpus_chunks, corpus_meta)]\n",
    "emb = model.encode(prepared, batch_size=BATCH, show_progress_bar=True)\n",
    "emb = np.array(emb).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c8094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Cell 9 — FAISS indexes\n",
    "# -----------------------------\n",
    "indexes = {cat: {\"index\": faiss.IndexFlatL2(emb.shape[1]), \"ids\": []} for cat in CATEGORIES}\n",
    "indexes[\"all\"] = {\"index\": faiss.IndexFlatL2(emb.shape[1]), \"ids\": []}\n",
    "\n",
    "\n",
    "for i, meta in enumerate(corpus_meta):\n",
    "    cat = meta[\"category\"] if meta[\"category\"] in CATEGORIES else \"all\"\n",
    "    indexes[cat][\"index\"].add(np.expand_dims(emb[i], 0))\n",
    "    indexes[cat][\"ids\"].append(i)\n",
    "    indexes[\"all\"][\"index\"].add(np.expand_dims(emb[i], 0))\n",
    "    indexes[\"all\"][\"ids\"].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa688db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:54<00:00, 54.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (44, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Cell 10 — Category detection\n",
    "# -----------------------------\n",
    "def detect_category(q):\n",
    "    q = q.lower()\n",
    "    if any(k in q for k in [\"ليموزين\",\"مواصلات\",\"شحن\",\"طرد\"]): return \"transportation\"\n",
    "    if any(k in q for k in [\"جامعة\",\"مقررات\",\"قبول\",\"كشف\"]): return \"education\"\n",
    "    if any(k in q for k in [\"طب\",\"حمد\",\"صحي\"]): return \"health\"\n",
    "    if any(k in q for k in [\"سجل\",\"ترخيص\",\"تمويل\",\"قرض\"]): return \"business\"\n",
    "    if any(k in q for k in [\"محكمة\",\"دعوى\",\"مرافعة\"]): return \"justice\"\n",
    "    if any(k in q for k in [\"سند\",\"إسكان\"]): return \"housing\"\n",
    "    if any(k in q for k in [\"شارك\",\"استبيان\",\"مشاركة\"]): return \"info\"\n",
    "    return \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14456149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Cell 11 — Retrieval (with reranker)\n",
    "# -----------------------------\n",
    "reranker = CrossEncoder(\"cross-encoder/ms-marco-mminiLM-L-6-v2\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def retrieve(query, top_k=5):\n",
    "    lang = detect_lang(query)\n",
    "\n",
    "\n",
    "    # Step 1 — Translate to Arabic if English\n",
    "    if lang == \"en\":\n",
    "        query_ar = translate_openai(query, tgt=\"ar\")\n",
    "    else:\n",
    "        query_ar = query\n",
    "\n",
    "\n",
    "    query_ar = normalize_arabic(query_ar)\n",
    "\n",
    "\n",
    "    # Step 2 — Category routing\n",
    "    cat = detect_category(query_ar)\n",
    "    idx = indexes.get(cat, indexes[\"all\"])\n",
    "\n",
    "\n",
    "    # Step 3 — Embedding search\n",
    "    q_emb = model.encode([\"query: \" + query_ar])\n",
    "    D, I = idx[\"index\"].search(np.array(q_emb).astype('float32'), top_k)\n",
    "\n",
    "\n",
    "    raw_results = []\n",
    "    for local_i in I[0]:\n",
    "        if local_i < 0: continue\n",
    "        global_id = idx[\"ids\"][local_i]\n",
    "        raw_results.append({\n",
    "            \"meta\": corpus_meta[global_id],\n",
    "            \"text\": corpus_chunks[global_id]\n",
    "        })\n",
    "\n",
    "\n",
    "    # Step 4 — Cross-encoder rerank\n",
    "    pairs = [(query_ar, r[\"text\"]) for r in raw_results]\n",
    "    scores = reranker.predict(pairs)\n",
    "\n",
    "\n",
    "    reranked = sorted(zip(raw_results, scores), key=lambda x: x[1], reverse=True)\n",
    "    return [r for r,_ in reranked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2573be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Cell 12 — LLM answer synthesis\n",
    "# -----------------------------\n",
    "def synthesize_answer(query, retrieved):\n",
    "    chunks_text = \"\\n\\n\".join(r[\"text\"] for r in retrieved)\n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    اجب عن السؤال التالي باستخدام المعلومات في النصوص بدقة.\n",
    "   السؤال: {query}\n",
    "\n",
    "\n",
    "    النصوص:\n",
    "    {chunks_text}\n",
    "\n",
    "\n",
    "    اكتب الجواب بالعربية الفصحى.\n",
    "    \"\"\"  \n",
    "\n",
    "\n",
    "    resp = oi.responses.create(model=\"gpt-4.1-mini\", input=prompt)\n",
    "    return resp.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c6734f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes saved to ../index\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Cell 13 — Query handler\n",
    "# -----------------------------\n",
    "def answer(query):\n",
    "    results = retrieve(query, top_k=5)\n",
    "    arabic_answer = synthesize_answer(query, results[:3])\n",
    "\n",
    "\n",
    "    # If user asked in English → translate back to English\n",
    "    if detect_lang(query) == \"en\":\n",
    "        return translate_openai(arabic_answer, tgt=\"en\")\n",
    "    return arabic_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b852b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Cell 14 — Example\n",
    "# -----------------------------\n",
    "print(answer(\"How do I rent a limousine in Qatar?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
