{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Visualization\n",
    "\n",
    "Visual analysis of system performance metrics and experimental results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Overall System Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall metrics\n",
    "metrics = {\n",
    "    'Overall Accuracy': 96.0,\n",
    "    'Arabic Accuracy': 96.0,\n",
    "    'English Accuracy': 96.0,\n",
    "    'Precision@3': 98.0,\n",
    "    'Precision@5': 98.0\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.barh(list(metrics.keys()), list(metrics.values()), color='#2E86AB')\n",
    "ax.set_xlabel('Accuracy (%)', fontsize=12)\n",
    "ax.set_title('System Performance Metrics', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim(0, 100)\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    ax.text(width + 1, bar.get_y() + bar.get_height()/2, \n",
    "            f'{width:.1f}%', ha='left', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Category Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category performance\n",
    "categories = {\n",
    "    'Business': (14, 14, 100),\n",
    "    'Culture': (10, 10, 100),\n",
    "    'Education': (16, 16, 100),\n",
    "    'Health': (16, 16, 100),\n",
    "    'Housing': (12, 12, 100),\n",
    "    'Info': (10, 10, 100),\n",
    "    'Transportation': (14, 14, 100),\n",
    "    'Justice': (4, 8, 50)\n",
    "}\n",
    "\n",
    "cat_names = list(categories.keys())\n",
    "accuracies = [v[2] for v in categories.values()]\n",
    "queries = [v[1] for v in categories.values()]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Accuracy by category\n",
    "colors = ['#A8DADC' if acc == 100 else '#E63946' for acc in accuracies]\n",
    "bars1 = ax1.bar(cat_names, accuracies, color=colors)\n",
    "ax1.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax1.set_title('Accuracy by Category', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylim(0, 110)\n",
    "ax1.axhline(y=96, color='gray', linestyle='--', alpha=0.5, label='Overall Average')\n",
    "ax1.legend()\n",
    "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "            f'{height:.0f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Queries by category\n",
    "bars2 = ax2.bar(cat_names, queries, color='#457B9D')\n",
    "ax2.set_ylabel('Number of Queries', fontsize=12)\n",
    "ax2.set_title('Test Queries by Category', fontsize=14, fontweight='bold')\n",
    "plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Add value labels\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.3,\n",
    "            f'{int(height)}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experiment 1: Translation Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation strategies comparison\n",
    "strategies = {\n",
    "    'Direct English': (100, 0.13),\n",
    "    'Multilingual': (100, 0.11),\n",
    "    'Translate + Embed': (83.3, 0.34),\n",
    "    'Back-translation': (83.3, 1.14)\n",
    "}\n",
    "\n",
    "strategy_names = list(strategies.keys())\n",
    "accuracies = [v[0] for v in strategies.values()]\n",
    "times = [v[1] for v in strategies.values()]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Accuracy comparison\n",
    "bars1 = ax1.bar(strategy_names, accuracies, color='#2A9D8F')\n",
    "ax1.set_ylabel('Precision@1 (%)', fontsize=12)\n",
    "ax1.set_title('Translation Strategy Accuracy', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylim(0, 110)\n",
    "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "            f'{height:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Response time comparison\n",
    "bars2 = ax2.bar(strategy_names, times, color='#E76F51')\n",
    "ax2.set_ylabel('Response Time (seconds)', fontsize=12)\n",
    "ax2.set_title('Translation Strategy Latency', fontsize=14, fontweight='bold')\n",
    "plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.05,\n",
    "            f'{height:.2f}s', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experiment 2: Hybrid Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hybrid retrieval comparison\n",
    "methods = {\n",
    "    'Semantic Only': 84,\n",
    "    'BM25 Only': 56,\n",
    "    'Hybrid 70/30': 80,\n",
    "    'Hybrid 50/50': 70,\n",
    "    'Cascade': 84\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = ['#06D6A0' if v >= 80 else '#EF476F' for v in methods.values()]\n",
    "bars = ax.bar(list(methods.keys()), list(methods.values()), color=colors)\n",
    "ax.set_ylabel('Precision@1 (%)', fontsize=12)\n",
    "ax.set_title('Hybrid Retrieval Methods Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim(0, 100)\n",
    "ax.axhline(y=84, color='gray', linestyle='--', alpha=0.5, label='Best Performance')\n",
    "ax.legend()\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "            f'{height:.0f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Experiment 4: Ablation Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablation study results\n",
    "configurations = {\n",
    "    'Full System': 96.0,\n",
    "    'Without Keyword\\nBoosting': 89.0,\n",
    "    'Without Title\\nMatching': 96.0,\n",
    "    'Pure Semantic\\n(Baseline)': 89.0\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = ['#118AB2' if v == 96 else '#FFB703' for v in configurations.values()]\n",
    "bars = ax.bar(list(configurations.keys()), list(configurations.values()), color=colors)\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax.set_title('Component Contribution (Ablation Study)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim(0, 100)\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "            f'{height:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Add contribution annotation\n",
    "ax.annotate('', xy=(0.5, 96), xytext=(0.5, 89),\n",
    "            arrowprops=dict(arrowstyle='<->', color='red', lw=2))\n",
    "ax.text(0.7, 92.5, '+7%\\nKeyword\\nBoosting', color='red', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. System vs Baseline Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System vs BM25 baseline\n",
    "comparison = {\n",
    "    'Our System': 96.0,\n",
    "    'BM25 Baseline': 56.0\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "bars = ax.bar(list(comparison.keys()), list(comparison.values()), \n",
    "              color=['#06D6A0', '#EF476F'], width=0.6)\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax.set_title('System Performance vs Baseline', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim(0, 110)\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "            f'{height:.1f}%', ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add improvement annotation\n",
    "ax.annotate('', xy=(0, 96), xytext=(0, 56),\n",
    "            arrowprops=dict(arrowstyle='<->', color='blue', lw=3))\n",
    "ax.text(-0.3, 76, '+40pp\\n(71% relative)', color='blue', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add statistical significance\n",
    "ax.text(0.5, 102, 'p < 0.0001', ha='center', fontsize=11, \n",
    "        bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Response Time Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Response time breakdown\n",
    "components = {\n",
    "    'Language\\nDetection': 0.05,\n",
    "    'Translation': 0.8,\n",
    "    'Embedding': 0.1,\n",
    "    'FAISS Search': 0.02,\n",
    "    'LLM Generation': 2.1\n",
    "}\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Bar chart\n",
    "bars = ax1.barh(list(components.keys()), list(components.values()), color='#F4A261')\n",
    "ax1.set_xlabel('Time (seconds)', fontsize=12)\n",
    "ax1.set_title('Response Time Breakdown', fontsize=14, fontweight='bold')\n",
    "\n",
    "for bar in bars:\n",
    "    width = bar.get_width()\n",
    "    ax1.text(width + 0.05, bar.get_y() + bar.get_height()/2,\n",
    "            f'{width:.2f}s', ha='left', va='center', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "colors_pie = ['#264653', '#2A9D8F', '#E9C46A', '#F4A261', '#E76F51']\n",
    "ax2.pie(list(components.values()), labels=list(components.keys()), autopct='%1.1f%%',\n",
    "        colors=colors_pie, startangle=90)\n",
    "ax2.set_title('Response Time Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTotal Response Time: {sum(components.values()):.2f}s\")\n",
    "print(f\"Average (without translation): {sum(components.values()) - 0.8:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table\n",
    "summary_data = {\n",
    "    'Metric': [\n",
    "        'Overall Accuracy',\n",
    "        'Arabic Accuracy',\n",
    "        'English Accuracy',\n",
    "        'Precision@3',\n",
    "        'Precision@5',\n",
    "        'MRR',\n",
    "        'NDCG@5',\n",
    "        'Response Time',\n",
    "        'Statistical Significance'\n",
    "    ],\n",
    "    'Value': [\n",
    "        '96.0% (96/100)',\n",
    "        '96.0% (48/50)',\n",
    "        '96.0% (48/50)',\n",
    "        '98.0%',\n",
    "        '98.0%',\n",
    "        '0.970',\n",
    "        '2.313',\n",
    "        '0.16s average',\n",
    "        'p < 0.0001'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(summary_data)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "table = ax.table(cellText=df.values, colLabels=df.columns,\n",
    "                cellLoc='left', loc='center',\n",
    "                colWidths=[0.5, 0.5])\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1, 2)\n",
    "\n",
    "# Style header\n",
    "for i in range(len(df.columns)):\n",
    "    table[(0, i)].set_facecolor('#2E86AB')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "# Alternate row colors\n",
    "for i in range(1, len(df) + 1):\n",
    "    for j in range(len(df.columns)):\n",
    "        if i % 2 == 0:\n",
    "            table[(i, j)].set_facecolor('#F0F0F0')\n",
    "\n",
    "plt.title('System Performance Summary', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The visualizations demonstrate:\n",
    "1. **High Accuracy:** 96% overall with equal cross-lingual performance\n",
    "2. **Statistical Significance:** p < 0.0001 vs BM25 baseline\n",
    "3. **Optimal Strategy:** Multilingual embeddings without translation\n",
    "4. **Key Component:** Keyword boosting contributes +7% accuracy\n",
    "5. **Limitation:** Justice category requires domain-specific handling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
